{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.transforms.functional import normalize\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "walldata = fetch_openml(name='wall-robot-navigation',version=3)\n",
    "\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(walldata.data, walldata.target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wall_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "X_wall_val = torch.from_numpy(X_val.to_numpy()).float()\n",
    "X_wall_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_wall_train = torch.from_numpy(y_train.to_numpy().astype(int)-1).long()\n",
    "y_wall_val = torch.from_numpy(y_val.to_numpy().astype(int)-1).long()\n",
    "y_wall_test = torch.from_numpy(y_test.to_numpy().astype(int)-1).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "wall_train_ds = TensorDataset(X_wall_train, y_wall_train)\n",
    "wall_train_dl = DataLoader(wall_train_ds, batch_size=bs)\n",
    "wall_val_ds = TensorDataset(X_wall_val, y_wall_val)\n",
    "wall_val_dl = DataLoader(wall_val_ds, batch_size=len(wall_val_ds))\n",
    "wall_test_ds = TensorDataset(X_wall_test, y_wall_test)\n",
    "wall_test_dl = DataLoader(wall_test_ds, batch_size=len(wall_test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indim = 4\n",
    "\n",
    "hiddim1 = 10\n",
    "hiddim2 = 10\n",
    "hiddim3 = 10\n",
    "\n",
    "outdim = 4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 500\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(indim,hiddim1,bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddim1,hiddim2,bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddim2,hiddim3,bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddim3,outdim,bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "size = len(wall_train_dl.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodenough = False\n",
    "goodenoughvalue = 0.99\n",
    "for epoch in range(epochs):\n",
    "    for batch, (X, y) in enumerate(wall_train_dl):\n",
    "\n",
    "        # All the training stuff\n",
    "\n",
    "        if ((epoch % 1 == 0) and (batch % 50 == 0)) or (loss.item() <= 0.001):\n",
    "            print(\"Epoch {} Batch {}: Training Loss = {}: Accuracy = {}\".format(epoch,batch,\n",
    "                                                        loss.item(),correct))\n",
    "            with torch.no_grad():\n",
    "                for X, y in wall_val_dl:\n",
    "                    pred = model(X)\n",
    "                    loss = loss_fn(pred, y)\n",
    "                    loss_value = loss.item()\n",
    "                    \n",
    "                    y_pred = torch.argmax(pred.data,1)\n",
    "                    correct = (y == y_pred).sum().item()/len(y_pred)\n",
    "                    if (epoch % 1 == 0) and (batch % 10 == 0):\n",
    "                        print(\"Validation Loss = {}: Accuracy = {}\".format(loss_value,correct))\n",
    "                    if correct >= goodenoughvalue:\n",
    "                        goodenough = True\n",
    "        if goodenough:\n",
    "            break\n",
    "    if goodenough:\n",
    "        break\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in wall_val_dl:\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        y_pred = torch.argmax(pred.data,1)\n",
    "        correct = (y == y_pred).sum().item()/len(y_pred)\n",
    "\n",
    "        print(\"Validation Loss = {}: Accuracy = {}\".format(loss_value,correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for X, y in wall_test_dl:\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        y_pred = torch.argmax(pred.data,1)\n",
    "        correct = (y == y_pred).sum().item()/len(y_pred)\n",
    "\n",
    "        print(\"Test Loss = {}: Accuracy = {}\".format(loss_value,correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "outchan1 = 10\n",
    "kernel1 = 5\n",
    "outchan2 = 20\n",
    "kernel2 = 5\n",
    "\n",
    "# For output sizing\n",
    "conv1 = torch.nn.Conv2d(1,outchan1,kernel1)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "conv2 = torch.nn.Conv2d(outchan1,outchan2,kernel2)\n",
    "\n",
    "print(X_crack_train[0:1].shape)\n",
    "print(conv1(X_crack_train[0:1]).shape)\n",
    "print(pool(conv1(X_crack_train[0:1])).shape)\n",
    "print(F.relu(pool(conv1(X_crack_train[0:1]))).shape)\n",
    "print(conv2(F.relu(pool(conv1(X_crack_train[0:1])))).shape)\n",
    "print(pool(conv2(F.relu(pool(conv1(X_crack_train[0:1]))))).shape)\n",
    "\n",
    "imgout = F.relu(pool(conv2(F.relu(pool(conv1(X_crack_train[0:1]))))))\n",
    "print(imgout.shape)\n",
    "\n",
    "infc1 = np.prod(imgout.shape)\n",
    "print(infc1)\n",
    "outfc1 = 50\n",
    "outfc2 = 2\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,outchan1,kernel1,outchan2,kernel2,infc1,outfc1,outfc2):\n",
    "        super(CNN,self).__init__()\n",
    "        self.infc1 = infc1\n",
    "        self.conv1 = torch.nn.Conv2d(1,outchan1,kernel1)\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        self.conv2 = torch.nn.Conv2d(outchan1,outchan2,kernel2)\n",
    "        self.fc1 = torch.nn.Linear(infc1,outfc1)\n",
    "        self.fc2 = torch.nn.Linear(outfc1,outfc2)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(-1,self.infc1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN(outchan1,kernel1,outchan2,kernel2,infc1,outfc1,outfc2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63239e487d98c7284e209f1e2423af1678d839c716ea06adfddffbe4e93e2bbb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
